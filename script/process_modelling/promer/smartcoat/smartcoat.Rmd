---
title: "Process Mining analysis on SmartCoat sqample data"
author: "Nima Ramezani Taghiabadi"
date: "17/08/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
if(!require("bupaR")) install.packages("bupaR")
if(!require("edeaR")) install.packages("edeaR")
if(!require("eventdataR")) install.packages("eventdataR")
if(!require("eventdataR")) install.packages("processmapR")
if(!require("processmonitR")) install.packages("processmonitR")
if(!require("processmapR")) install.packages("processmapR")
if(!require("xesreadR")) install.packages("xesreadR")
if(!require("petrinetR")) install.packages("petrinetR")
if(!require("daqapo")) install.packages("daqapo")
if(!require("processanimateR")) install.packages("processanimateR")

library(magrittr)
library(dplyr)
library(viser)

path.data = paste(getwd(), 'data', sep = '/')
path.promer = paste(getwd(), '..', '..', '..', '..','..','..', 'packages', 'promer', 'R', sep = '/')
path.gener = paste(getwd(),  '..', '..', '..', '..','..','..', 'packages', 'gener', 'R', sep = '/')

source(path.promer %>% paste('tsvis.R', sep = '/'))
source(path.promer %>% paste('transys.R', sep = '/'))

source(path.gener %>% paste('gener.R', sep = '/'))
source(path.gener %>% paste('linalg.R', sep = '/'))

##### Read Data ####
read.csv(path.data %>% paste('SmartCoat_Eventlog_March_2016.csv', sep = '/')) %>% 
  mutate(Timestamp = as.character(Timestamp) %>% lubridate::dmy_hm()) -> data

# x = TRANSYS()
# x$feed.eventlog(dataset = data, caseID_col = 'Case.ID', status_col = 'Activity.description', startTime_col = 'Timestamp', 
#                 caseStartFlag_col = NULL, caseEndFlag_col = NULL, caseStartTags = NULL, caseEndTags = NULL, 
#                 sort_startTime = T, add_start = T, remove_sst = F, 
#                 extra_col = c("Resource", "Location", "Brand", "Customer", "Estimated.activity.cost"))

```

## Preprocessing and creation of event-log object
The notion of event log refers to a set of events which are recorded in the context of a process. Each event belongs to a case. A case, in general is an instance of the process. 
### Activity Instance ID
Each event relates to the coarser concept of an **activity**. For instance, activities in our example are: 
`r data$Activity.description %>% unique %>% as.character %>% sample(4) %>% c('...') %>% paste(collapse = ', ')`.
When an activity is performed, this means that an activity instance is created. While the label **PICK-TO-COAT** refers to an activity, one specific PICK-TO-COAT for a specific phone at a specific point in time is an activity instance.
Since we don't have any column referring to avctivity instance, we create it by giving a unique number to each task.
```{r preprocessing_1}
data %<>% mutate(actince_id = paste(Case.ID, Activity.description, sep = '-'))
data %<>% group_by(Case.ID, Activity.description) %>% mutate(actince_id = Case.ID %>% paste(Activity.description, sequence(length(Case.ID)), sep = '-')) %>% ungroup
```


### Activity Life Cycle

Each row in the event-log is an atomic registration related to an activity instance. 
It thus contains one (and only one) timestamp. Additionally, the event should include a reference to a life cycle transition. 
More specificaly, multiple events can describe different stages of a single activity instance. These stages can be Arrival, Start, Completion and so on. For example, one event might record when a phone is scheduled for testing, another when it is started testing, yet another when the testing is completed.
We do not have activity life-cycle specified, we assume all activities are logged by the completion time, so we add
a **complete** tag to all activities as the activity life-cycle stage.

```{r preprocessing_2}
data %<>% mutate(actstage = 'complete')
```

Given that the data is in the required format, an event log object can be created. This object will be used later to generate all desired process mining analytics.

```{r el_object}
el = eventlog(eventlog = data, case_id = "Case.ID", activity_id = "Activity.description", timestamp = 'Timestamp',
               activity_instance_id = 'actince_id', resource_id = 'Resource', lifecycle_id = 'actstage')
summary(el)
```
## Transition System

A **Transition System** modelling is mostly used when cases have transitions through a limited number of **statuses**.
Transition Systems can give us a memory-less Markov-Chain model by which, we can have a first stimation transition probabilities.
A random-walk through this MK model, can describe long-term case probabilities for being in a certain status.

### Process Map
The first and most important output of a transition system is **Process Map** which is the most basic, 
but important visualtisation of the process.

By defining activities as stauses, a process map shows ratios of transitions through various activities during the life time of a case. Process maps also illustrate the average or total amount of time of activity transitions. 

By process map, one can find loops, process bottle-necks and/or degree of centrality of activities within the process. 
It also shows the diversity of process variations.

#### Frequency profile
By default, the process map is annotated with frequencies of activities and flows. The is what is called the **frequency profile**, and can be created explicitly using the frequency function. This function has a value argument, which can be used to adjust the frequencies shown, for instance using relative frequencies instead of the default absolute ones.
The frequency value displayed can be one of the following

##### Absolute Frequency
Shows the absolute number of activity instances and flows:
```{r process_map_1}
el %>% process_map(type = frequency("absolute"), rankdir = 'TB')
```

##### Absolute Case Frequency
Shows the absolute number of cases behind each activity and flow:

```{r process_map_2}
el %>% process_map(type = frequency("absolute-case"), rankdir = 'TB')
```

##### Relative Frequency
Shows:
* The relative number of instances per activity
* The relative outgoing flows for each activity

```{r process_map_3}
el %>% process_map(type = frequency("relative"), rankdir = 'TB')
```
##### Relative Case Frequency
Shows the relative number of cases per activity and flow:

```{r process_map_5}
el %>% process_map(type = frequency("relative-case"), rankdir = 'TB')
```

#### Performance profile

Performance profile, focuses on processing time of activities. The type of performance profile is defined with two characteristics: 
* **Aggregator Function** to be applied on the processing time (e.g. min, max, mean, median, etc.)
* **Time Unit** to be shown on the process map:

```{r process_map_6}
el %>% process_map(type = performance(median, "hours"), rankdir = 'TB')
```

The values on the dircted links on the process map show median transition time in hours. 
One can easily find out which transitions take more than expected time.

#### Simplifying process maps
When event-logs is large, they will also become more unstructured, and this leads to a noisy process maps which is not only hard to understand, but also expensive to generate. In such cases, it is useful to apply a coverage filtering on the event log. The filtering is done in case level which means cases with process varioations (traces) in minority, will be removed to simplify the process map. 
Below, a simplified relative-case frequency process map is shown using a 40% Coverage rate:
```{r process_map_7}
el %>% filter_trace_frequency(percentage = 0.4) %>% process_map(type = frequency("relative-case"), rankdir = 'TB')
```

#### Animated Process Map
Process mining tools can also show animated process maps which show how cases (called tokens in a process model) flow through the process map. One can focus on a particular case to see how long cases are lingering in each activity or transition.
In the following, you see a basic animation with static color and token size:

```{r process_map_8}
el %>% animate_process()
```

We can even change token colors by time based on the employee who works on the case by that time. This can give us a fast visual understanding of employee's time working on various tasks:

```{r process_map_9}
animate_process(el, mode = "relative", jitter = 10, legend = "color",
  mapping = token_aes(color = token_scale("Resource", 
    scale = "ordinal", 
    range = RColorBrewer::brewer.pal(7, "Paired"))))
```

### Precedence diagrams
A **precendence diagram** is a matrix showing the flows between activities. It can contain different type of values:

* Absolute frequency of flows
* Relative frequency of flows
* Relative frequency of flows, for each antecendent task. 
  For example, given task A is completed, it is followed x% of the time by task B
* Relative frequency of flows, for each consequent task
  For example, given token enters task B, it is preceded x% of the time by task A

Below, an example of Relative frequency matrix is shown:

```{r diagram_1}
el %>% precedence_matrix(type = "absolute") %>% plot
```

### Dot Charts
A **Dot Chart** is a chart in which each activity instance is displayed with a point. The horizontal axis shows the time aspect, while the vertical axis refers to cases.
In the following dot chart, dot color represent the employee, so you can see those employees whose contributions are mostly at the beginning or end of the process or distributed evenly. It also shows the distribution of end-to-end process time. 
For example you can see that 9 cases took longer than 3 weeks which 7 of them were completed by Jerome.
```{r dchart_1}
el %>% dotted_chart(x = "relative", y = "duration", color = "Resource")
```


## Metrics

The most important metrics describing a process can be categorised to five groups:

* Time perspective

+ throughput time: the time between the very first event of the case and the very last
+ processing time: the sum of the duration of all activity instances
+ idle time: the time when no activity instance is active
  To get the idle-time report, we need to make sure every activity of the resources is logged in the event-log. If resources do something which takes some time and those activities are missing from the event-log, an idle-times report, will be inaccurate. For this example, since we do not have task life-cycle stages in this sample data (like start and end of an activity) we cannot generate report of resource idle time.
  
## Live Dashboard (Process Monitoring)

We can provide a live dashboard where you can see various insights all in one place.
This dashboard can be customized based on the specific business requirements and priorities.

In a live dashboard, the user will be able to customize the visualisation to what he/she wants.
You can filter cases on whatever features you desire, and select whatever type of process map you like to generate.

Other than what shown here, there are many more visualisations and insights you can get from process mining.


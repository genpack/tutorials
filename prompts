##### Initiative Proposal Review

# Prompt 1:

You are an AI assistant. Your job is to review initiatives proposed in a bank based on the follwing criteria.
These are questions you need to ask yourself and give a score of 1-3 for each question.

Scoring metric:

1- Unclear/Not Confident 
2- Mirky/unsure 
3- Clear/Confident

You are also asked to provide a short overall comment about the initiative
just to give someone reviewing an idea of why yes or why no.

Assessment Criteria:
  
  1- Problem Statement:
    Can you clearly understand the problem they are trying to solve?
    Do you know why this is a problem and who is impacted by it? 
    Have they given a high level overview of how they would solve the problem? 
  2- Solution:
    Do you clearly understand the solution they are working on? 
    Are they solving a problem worth fixing? 
    Are you clear on whether the suggested solution will solve for the problem statement? 
  3- Impact & Reach:
    Are you clear on the impact solving this problem will have? 
    Will the time invested in solving the problem result in a tangible impact? 
    Can the solution be scaled to solve for the problem statement? 
  4- Resources & Dependencies 
    Are you clear on what data & tools will be used to resolved the problem? 
    Are you clear on whether they have access to the data available to them to build a solution?
    Do you know how teams will measure their solution? 
  5- Strategic Review:
    Is it worthwhile building this prototype? 
    Does it sit within our current tech strategy? 

# Reply from AI:


# Prompt 2:

Problem 

What is the problem you are trying to solve?

We are solving the problem of unstructured performance feedback from Workday feedback PDFs by using GenAI to transform them into clear, KPI-aligned summaries for employees and managers.
What is the problem statement theme you feel your problem aligns to and why do you feel it aligns to that theme? 

Employee Engagement and Experience.
Explain why this is a problem, who is impacted and why it is worth solving? 

Manual review of unstructured performance feedback is inefficient, inconsistent, and limits the ability to align individual contributions to organizational goals
Explain the problem in more detail:
Who is impacted:
Managers: Must manually read and interpret feedback for all direct reports
Employees: Receive vague or inconsistent growth feedback
HR & Leadership: Lack visibility into performance trends across teams
Why should we spent time solving this:
Enables consistent, KPI-aligned feedback
Reduces review preparation time for managers
Enhances employee development and engagement
Converts static PDFs into an actionable knowledge base
How will your solution address the problem statement:
The GenAI Performance Feedback Analyzer transforms unstructured Workday PDFs into structured, KPI-aligned summaries using Amazon Bedrock. This end-to-end solution integrates with AWS DHP services—S3, Bedrock, and knowledgebase—and delivers a secure, role-based interface to help employees reflect and grow, while enabling managers to make consistent, data-driven assessments.

Describe the solution in detail, including key features and functionalities.
DHP (Bedrock) and GenAI Studio will be available for use
We propose a GenAI-powered Performance Feedback Analyzer that automates the transformation of Workday-generated PDF feedback files into structured summaries aligned with our organization’s KPIs and values. The solution uses Amazon Bedrock and AWS DHP services to extract and summarize data, stores it in a knowledge base, and delivers insights through a secure, interactive web app hosted on EC2 or ECS. This tool empowers employees and managers to engage in more effective, data-driven performance conversations.
We will build a GenAI-powered analyzer that:
Reads feedback PDF files from Workday and stores it in Amazon S3
Uses Amazon Bedrock (LLM models) to summarize achievements, strengths, and improvement areas
Provides a secure, role-based web app for employees and managers to access personalized insights.

Extract Feedback -> Store Securely -> Summarise with GenAI -> Display Insights

Describe the impact of the solution on the customers identified. 

The solution helps employees understand feedback clearly, saves managers time, and gives HR visibility into performance trends.
Empowers employees with clearer understanding of their feedback and growth areas.
Saves time for managers and gives HR visibility into performance trends.
Does this solution have the potential be more widely adopted?

Can be applied across HR, I&D, and manager groups for automated feedback summarization.
Supports consistent performance insights from unstructured feedback across teams.
 
By what methods will you be able to measure the success of the solution? 
Track time saved, adoption rate, and clarity ratings from users.
Compare AI-generated summaries with manual versions for accuracy.

It simplifies feedback, aligns it to KPIs, and delivers summaries via a secure web app.
direct hit


# Reply from AI:

| **Criterion**                    | **Question**                                                      | **Score** | **Quick rationale**                                                                 |
| -------------------------------- | ----------------------------------------------------------------- | --------- | ----------------------------------------------------------------------------------- |
| **1 · Problem Statement**        | 1 · Do we clearly understand the problem?                         | **3**     | Pain‑point (unstructured Workday PDFs) is explicit.                                 |
|                                  | 2 · Do we know why it’s a problem & who is impacted?              | **3**     | Managers, employees, HR all listed with concrete pain.                              |
|                                  | 3 · Have they given a high‑level overview of how they’d solve it? | **3**     | “Extract → Summarise → Display” pipeline spelled out.                               |
| **2 · Solution**                 | 1 · Do we clearly understand the solution?                        | **3**     | Tech stack (S3, Bedrock, web app) and flow are clear.                               |
|                                  | 2 · Is the problem worth fixing?                                  | **3**     | Direct link to engagement, efficiency, KPI alignment.                               |
|                                  | 3 · Will the solution address the problem statement?              | **2**     | Conceptually yes, but success depends on LLM accuracy & change‑management.          |
| **3 · Impact & Reach**           | 1 · Is the impact clear?                                          | **3**     | Time‑saved, clarity, HR insight stated.                                             |
|                                  | 2 · Will the effort yield tangible impact?                        | **2**     | Benefits plausible, but ROI estimates / baseline metrics not yet shown.             |
|                                  | 3 · Can the solution scale?                                       | **2**     | Re‑usable across teams, yet depends on Workday data access & model cost.            |
| **4 · Resources & Dependencies** | 1 · Are data & tools clear?                                       | **3**     | PDFs from Workday, AWS stack listed.                                                |
|                                  | 2 · Do they have data access?                                     | **2**     | Assumed but not confirmed; Workday export and privacy hurdles unaddressed.          |
|                                  | 3 · Do we know how they’ll measure success?                       | **2**     | “Time saved, adoption, clarity ratings” named—needs concrete targets.               |
| **5 · Strategic Review**         | 1 · Is it worthwhile to prototype?                                | **3**     | Low‑code POC could validate GenAI value quickly.                                    |
|                                  | 2 · Does it fit our tech strategy?                                | **2**     | Uses AWS (aligned with DHP) but requires confirmation vs internal GenAI guardrails. |

**Clarifying scoring framework**

It looks like I'm considering how to score each criterion, using sub-questions (Q1, Q2, Q3) for each criterion. The table I initially proposed includes those sub-questions. However, the spec suggests scoring each question (1-3), and the table previously showed a single "Score (1-3)" per criterion. I’m thinking the final score might be an average for each criterion based on the sub-questions, but the spec isn’t completely clear whether I should score sub-questions individually or only aggregate them. I'll need to sort this out.

**Clarifying scoring approach**

I need to evaluate an initiative using a score of 1-3 for each sub-question. There are 5 main criteria with sub-questions (each criterion having 2–3 sub-questions). The plan is to score each sub-question, but I wonder if I should aggregate those scores into one per criterion or keep individual scores for each sub-question. I assume the aggregation might be simpler. So, I need to provide a total of 14 scores (3 per criterion, except for Strategic Review with 2).


Thought for 17 seconds


### GenAI Performance Feedback Analyzer – Rapid Review

| **Criterion**                    | **Question**                                                      | **Score** | **Quick rationale**                                                                 |
| -------------------------------- | ----------------------------------------------------------------- | --------- | ----------------------------------------------------------------------------------- |
| **1 · Problem Statement**        | 1 · Do we clearly understand the problem?                         | **3**     | Pain‑point (unstructured Workday PDFs) is explicit.                                 |
|                                  | 2 · Do we know why it’s a problem & who is impacted?              | **3**     | Managers, employees, HR all listed with concrete pain.                              |
|                                  | 3 · Have they given a high‑level overview of how they’d solve it? | **3**     | “Extract → Summarise → Display” pipeline spelled out.                               |
| **2 · Solution**                 | 1 · Do we clearly understand the solution?                        | **3**     | Tech stack (S3, Bedrock, web app) and flow are clear.                               |
|                                  | 2 · Is the problem worth fixing?                                  | **3**     | Direct link to engagement, efficiency, KPI alignment.                               |
|                                  | 3 · Will the solution address the problem statement?              | **2**     | Conceptually yes, but success depends on LLM accuracy & change‑management.          |
| **3 · Impact & Reach**           | 1 · Is the impact clear?                                          | **3**     | Time‑saved, clarity, HR insight stated.                                             |
|                                  | 2 · Will the effort yield tangible impact?                        | **2**     | Benefits plausible, but ROI estimates / baseline metrics not yet shown.             |
|                                  | 3 · Can the solution scale?                                       | **2**     | Re‑usable across teams, yet depends on Workday data access & model cost.            |
| **4 · Resources & Dependencies** | 1 · Are data & tools clear?                                       | **3**     | PDFs from Workday, AWS stack listed.                                                |
|                                  | 2 · Do they have data access?                                     | **2**     | Assumed but not confirmed; Workday export and privacy hurdles unaddressed.          |
|                                  | 3 · Do we know how they’ll measure success?                       | **2**     | “Time saved, adoption, clarity ratings” named—needs concrete targets.               |
| **5 · Strategic Review**         | 1 · Is it worthwhile to prototype?                                | **3**     | Low‑code POC could validate GenAI value quickly.                                    |
|                                  | 2 · Does it fit our tech strategy?                                | **2**     | Uses AWS (aligned with DHP) but requires confirmation vs internal GenAI guardrails. |

---

#### Overall comment

A well‑articulated pain‑point with a clear GenAI pipeline that leverages existing AWS capabilities; promising for boosting feedback quality and manager efficiency. Key next steps: validate Workday data access/permissions, set measurable success KPIs, and pilot to verify LLM accuracy and user adoption before full rollout.

# Prompt 3:

# Reply from AI:


# Prompt 4:

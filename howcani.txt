How  can I:

## change environmental variables in R environment [27 Dec 2018]:
> Sys.setenv("VAR1" = "value1", "VAR2" = "value2", ...)

## get the value of an environmental variable in R environment [27 Dec 2018]:
> Sys.getenv("VAR1")

## run R command in shell environment [27 Dec 2018]:
Examples:
$ sudo R -e 'install.packages("curl", repos = "http://cran.dev.abc/", lib = "/usr/lib64/R/library/")'
$ R -e 'source("C:/R/myfile.R"); df = read.csv("C:/data/mydata.cdv")'

## install libcurl in redhat [27 Dec 2018]
$ sudo yum -y install libcurl libcurl-devel

## start/stop shinyserver  [27 Dec 2018]:
$ sudo systemctl stop shiny-server
$ sudo systemctl start shiny-server

## find where rpm has installed a package in redhat [27 Dec 2018]:
$ rpm -ql <package_name>

## upload a file to s3 bucket in shell environment [27 Dec 2018]:
$ aws s3 cp <local_address> <s3_address> --profile <your_role>@<your_profile> 
Example:
$ aws s3 cp ~/Documents/data/stky/bigeventlog.csv s3://staging.dmclnt.elsrvcs.com/bigeventlog.csv --profile write@billing

## download a file from s3 bucket in shell environment [27 Dec 2018]:
$ aws s3 cp <s3_address> <local_address> --profile <your_role>@<your_profile> 
Example:
$ aws s3 cp s3://staging.dmclnt.elsrvcs.com/bigeventlog.csv ~/Documents/data/stky/bigeventlog.csv --profile write@billing

## see list of all environmental variables in linux shell [27 Dec 2018]:
$ env

## see the value of an environmental variables in windows shell [22 Jan 2019]:
Example:
$ echo %PATH%


## remotely connect to AWS EMR cluster [27 Dec 2018]:
To connect to an aws EMR cluster:
1- You need to know the uri of your cluster which is referred to as : Master Public DNS
Examples of uri to an EMR cluster:
hadoop@ec2-34-172-254-276.compute-1.amazonaws.com
hadoop@ ec2-67-42-216-27.ap-southeast-2.compute.amazonaws.com
2- You also need a key to open the gate. This key is a small file with extension .pem (or .ppk)
This file contains a RSA256 hashed key for ssh connection:
You need to set permissions for your keys otherwise your connection will come with an error saying the keys are too open and not really secure:
$ chmod 400 ~/mykeypair.pem 
Reading this can help:
https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-connect-master-node-ssh.html
3 - To connect remotely to the cluster with ssh:
$ ssh hadoop@<EMR URI> -I <your key>
Examples:
$ ssh hadoop@emr.14d1456q-2621-a8ba-fcca-9d15d9f22ae9.stky.elsrvcs.com -i ~/dmclnt.pem

## to copy a folder recursively with all attributes in linux shell [27 Dec 2018]:
$ cp -rp <source_address> <destination_address>
Example:
$ sudo cp -rp smartoptimiser sodc

## copy files from one machine to another using ssh [27 Dec 2018]:
Send:
$ scp <source_address> <username>@<destination_machine_uri>:<destination_address>
Receive:
$ scp <username>@<destination_machine_uri>:<destination_address> <source_address> 
In case the remote machine uses ssh or identity file for authorisation (rather than username & password)
use -i (for identity file) or -F (for ssh key)
Example:
$ sudo scp -i ~/dmclnt.pem config.yml hadoop@emr.79c1756b-2621-a8ba-fcca-8b07d9f22ae9.stky.elsrvcs.com:~/

## get the list of files in a directory in R environment:
> list.files(path = '.')

## publish RStudio Server as a web interface on AWS EMR cluster or EC2 instance [28 Dec 2018]:
1- [remotely connect to] AWS EMR cluster
2- install R on the instance
3- [install Rstudio server] on the instance
4- [make a new user with password]
5- To connect remotely to the app, on each client, you need to [build a tunnel with dynamic port forwarding]
6- [set proxy settings via foxyproxy] on the client with the same port number you build the tunnel trough. Make sure the instance uri will pass the url patterns (regex/wildcard filters) specified in the proxy settings.
7- By default RStudio Server runs on port 8787. To connect, on the client browser: http://<server-ip>:8787
Reading this can help:
https://spark.rstudio.com/examples/yarn-cluster-emr/

## install Rstudio server on any redhat linux machine [28 Dec 2018]:
$ sudo yum update
$ sudo yum install libcurl-devel openssl-devel
$ wget -P /tmp https://s3.amazonaws.com/rstudio-dailybuilds/rstudio-server-rhel-0.99.1266-x86_64.rpm
$ sudo yum install --nogpgcheck /tmp/rstudio-server-rhel-0.99.1266-x86_64.rpm
By default RStudio Server runs on port 8787. To connect, on the client browser: http://<server-ip>:8787

## make a new user with password on linux shell:
$ sudo useradd -m <username>
$ sudo passwd <username>
enter a new password or change old password

## build a tunnel with dynamic port forwarding to an aws instance
$ ssh -i <your_key> -N -D <port_number> <username>@<remote_machine_uri>
Example:
$ ssh -i ~/dmclnt.pem -N -D 8157 hadoop@emr.49c1146b-2411-a8ba-fcca-8b07d9f22ae9.stky.elsrvcs.com
https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-connect-master-node-proxy.html

## set proxy settings via foxyproxy in google chrome [28 Dec 2018]:
1- install foxyproxy in google chrome
2- go to chrome and right-click on the blue foxyproxy extension icon on the upper right (right after the address bar) --> select options
3- add a new or edit an existing proxy settings (you can either add a new proxy settings manually or import it from a xml file)
3.1- to add a new proxy settings manually:
3.1.1 click on add new proxy
3.1.2 in General tab, select a name and some describing notes and a color for the new proxy settings you are going to add
3.1.3 in Proxy Details tab, manually write all the specifications 
3.1.4 in URL Patterns tab, manually add all the patterns 
3.2- to import proxy settings from xml file:
3.2.1- make a xml text file with any editor. This file can contain multiple proxy settings. The xml file should be like this example:
<?xml version="1.0" encoding="UTF-8"?>
<foxyproxy>
   <proxies>
      <proxy name="emr-socks-proxy" id="2322596116" notes="" fromSubscription="false" enabled="true" mode="manual" selectedTabIndex="2" lastresort="false" animatedIcons="true" includeInCycle="true" color="#0055E5" proxyDNS="true" noInternalIPs="false" autoconfMode="pac" clearCacheBeforeUse="false" disableCache="false" clearCookiesBeforeUse="false" rejectCookies="false">
         <matches>
            <match enabled="true" name="*ec2*.amazonaws.com*" pattern="*ec2*.amazonaws.com*" isRegEx="false" isBlackList="false" isMultiLine="false" caseSensitive="false" fromSubscription="false" />
            <match enabled="true" name="*ec2*.compute*" pattern="*ec2*.compute*" isRegEx="false" isBlackList="false" isMultiLine="false" caseSensitive="false" fromSubscription="false" />
            <match enabled="true" name="10.*" pattern="http://10.*" isRegEx="false" isBlackList="false" isMultiLine="false" caseSensitive="false" fromSubscription="false" />
            <match enabled="true" name="*10*.amazonaws.com*" pattern="*10*.amazonaws.com*" isRegEx="false" isBlackList="false" isMultiLine="false" caseSensitive="false" fromSubscription="false" />
            <match enabled="true" name="*10*.compute*" pattern="*10*.compute*" isRegEx="false" isBlackList="false" isMultiLine="false" caseSensitive="false" fromSubscription="false" /> 
            <match enabled="true" name="*.compute.internal*" pattern="*.compute.internal*" isRegEx="false" isBlackList="false" isMultiLine="false" caseSensitive="false" fromSubscription="false"/>
            <match enabled="true" name="*.ec2.internal* " pattern="*.ec2.internal*" isRegEx="false" isBlackList="false" isMultiLine="false" caseSensitive="false" fromSubscription="false"/>	  
	   </matches>
         <manualconf host="localhost" port="8157" socksversion="5" isSocks="true" username="" password="" domain="" />
      </proxy>
   </proxies>
</foxyproxy>
3.2.2- On the FoxyProxy page, choose Import/Export, choose the xml file you created

## select a set of most relevant features for your ML models [02 Jan 2019]:
Reading these links will help:
https://blog.bigml.com/2014/02/26/smart-feature-selection-with-scikit-learn-and-bigmls-api/
https://github.com/cheesinglee/bigml-feature-subsets
https://arxiv.org/pdf/1812.09044.pdf


## download some dataset for machine learning or other purposes [02 Jan 2019]:
http://archive.ics.uci.edu/ml/index.php

## detect concept drift in machine learning [02 Jan 2019]:
What is concept drift?
https://en.wikipedia.org/wiki/Concept_drift#Datasets
Methods to detect:
http://www.liaad.up.pt/area/jgama/DataStreamsCRC.pdf
http://www.lsi.upc.edu/~abifet/EDDM.pdf

## Read a csv text file [03 Jan 2019]:
Into R data.frame: read.csv(filename, ...)
In Python pandas dataframe: pandas.read_csv(filename, ...)

## add a header with column names to a table [04 Jan 2019]:
Python pandas DataFrame:
data = pandas.DataFrame(data.values, columns = ['col1', 'col2'])

## run spark jobs on emr cluster [06 Jan 2019]: (not complete)
aws emr add-steps --cluster-id <cluster_id> --steps "Type=spark,Name=<job_name>,Args=[--args1,values1,--args2,values2,--args3,values3,...]" --profile <profile>@<role>
Example:
aws emr add-steps --cluster-id j-742YEJR5HYJE --steps Type=spark,Name=PeriodicAggregatorJob,Args=[--deploy-mode,cluster,--master,yarn,--conf,spark.yarn.submit.waitAppCompletion=true,s3://stky.dmclnt.elsrvcs.com/spark_jobs/periodicAggregator.py,s3://stky.dmclnt.elsrvcs.com/configurations/periodicAggregator_config.yml],ActionOnFailure=CONTINUE --profile admin@stky-demo
Read:
https://docs.aws.amazon.com/cli/latest/reference/emr/add-steps.html
https://aws.amazon.com/premiumsupport/knowledge-center/emr-submit-spark-job-remote-cluster/
https://stackoverflow.com/questions/34664090/how-do-i-setup-and-run-sparkr-projects-and-scripts-like-a-jar-file

## deal with categorical variables with large domain in machine learning [07 Jan 2019]: 
Read about fused lasso:
https://stats.stackexchange.com/questions/146907/principled-way-of-collapsing-categorical-variables-with-many-levels
http://dept.stat.lsa.umich.edu/~jizhu/pubs/Tibs-JRSSB05.pdf
With R: https://www.rdocumentation.org/packages/lqa/versions/1.0-3/topics/fused.lasso
https://www.researchgate.net/publication/265615582_User's_Guide_to_lqa
With Python:

## install a python package from remote repository [08 Jan 2019]:
$ pip install git+<repo_url>
Example:
$ pip install git+https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/elib
In Python environment:
>>> !pip install git+<repo_url>

## find address of a variable in R [17 Jan 2019]:
> pryr::address(x)

## find a website to download forex rates [19 Jan 2019]:
https://www.rba.gov.au/statistics/historical-data.html
R package quantmod also gives you API to download, but only the latest 180 days!

## run parallel tasks on sparkR [24 Jan 2019]:
https://databricks.com/session/parallelizing-existing-r-packages-with-sparkr
https://stackoverflow.com/questions/34670006/parallelize-not-working-sparkr
https://blog.rstudio.com/2015/05/28/sparkr-preview-by-vincent-warmerdam/

## list all branches in a git repository from command line [25 Jan 2019]:
$ git branch -a

## switch to a branch in a git repository from command line [25 Jan 2019]:
$ git checkout <branch_name>
Example:
$ git checkout develop

## create a new branch with git [28 Apr 2022]:
$ git checkout -b <branch-name>

## update a branch in the local copy from a git repository from command line [25 Jan 2019]:
$ git pull <repository_name> <branch_name>
Examples:
$ git pull origin develop
$ git pull repo2 master

## dump a python dictionary to a YAML document [29 Jan 2019]:
>>> import yaml
>>> dictionary = {"a": [1, 2], "b": [4, 5]}
>>> print yaml.dump(dictionary)

## run Time-series event-based prediction [06 Feb 2019]:
https://www.researchgate.net/publication/271539746_Time-series_event-based_prediction_An_unsupervised_learning_framework_based_on_genetic_programming

## train LSTM model with R [06 Feb 2019]:
https://www.kaggle.com/taindow/simple-lstm-with-r

## use TensorFlow in R [06 Feb 2019]:
https://tensorflow.rstudio.com/tensorflow/articles/using_tensorflow_api.html

## fit distributions in python with scipy [06 Feb 2019]:
https://docs.scipy.org/doc/scipy/reference/stats.html

## install a python package on windows [09 Feb 2019]:
goto the python folder
Example:
> cd C:\Users\nicolas_\AppData\Local\Programs\Python\Python37
> python -m pip install --upgrade pip
> cd Scripts
> pip install tensorflow
> pip.exe install keras

## Assign multiple new variables on LHS in a single line in R [11 Feb 2019]:
option 1 Example: 
>>> list(x = 12, Y = 'Hello') %>% list2env(.GlobalEnv)
option 2 Example: 
>>> library(zeallot)
>>> c(x, Y) %<-% list(x = 12, Y = 'Hello')


## find list of best R packages [06 Feb 2019]:
https://www.computerworld.com/article/2921176/business-intelligence/great-r-packages-for-data-import-wrangling-visualization.html

## see list of files in s3 bucket folder [13 Feb 2019]:
$ aws s3 ls <s3_bucket>/path/to/your/directory/
Example:
$ aws s3 ls s3://em.prd.stcy.wp.els.com/run=283f037c-d5c2-476a-9c5f-4322f72d4173/data/


## find all data types in athena sql [18 Feb 2019]:
https://docs.aws.amazon.com/athena/latest/ug/data-types.html

## find some eventlog sample data for process mining [14 Mar 2019]:
https://data.4tu.nl/repository/collection:event_logs_real

## Get a list of all s3 buckets you have [11 May 2019]:
$ aws s3 ls

## Get a list of all repositories you have in aws codecommit [11 May 2019]:
$ aws codecommit list-repositories

## Get detail information of a codecommit repository in aws [11 May 2019]:
$ aws codecommit get-repository --repository-name <repo_name>

##  install docker on the RHEL machine [30 Jan 2018]:
Example:
[Berta@s029ndpl0703 ~]$sudo yum -y install docker --installroot=/mnt/test/ --nogpgcheck

## to find which versions of each software is available on the RHEL system [30 Jan 2018]:
Examples:
$sudo yum list docker  --showduplicates | sort -r
$sudo yum list R  --showduplicates | sort -r

##  install a specific version of a python package [22 Jan 2020]:
Example:
$ pip install tensorflow~=1.15.0 --user
(--user is required when modification access is denied on other folders)

## run a model in the el pipeline [10 Feb 2020]:
1-pull/checkout/update a local copy of stcky repository:
2-in folder tools look for credentials.yaml and edit it with a text editor
3-enter your username and api-key
4-after setting the credentials, goto tools -> Configs --> Prediction (you can submit other types of job like mlmapper, eventmapper and sampler jobs as well). In each folder, there are some internal folders. Each folder is for a projects(clients). Within each client-folder, there are multiple config-folders with a config.yaml file in it. Open your own config-folder and put your config.yaml file in it.
5-In folder tools, there are jupyter notebook files named as: 01_Obs_Mapper.ipynb, 02_Event_Mapper.ipynb, .... Open file 05_Prediction.ipynb
6-Install all the packages you need. yaml must be version 5.1.2
$pip install --ignore-installed pyyaml==5.1.2
7-Choose client, choose your config file and submit model after verifying 
8-click on get jobs to see the result

## merge a develop branch to the master with git command line [24 Feb 2020]:
# Example:
git checkout branch -> git status -> git add -> git commit -m "something" -> git pull -> git push origin develop -> git checkout master -> git merge develop -> git push origin master
If you want to add a tag: 
# example: (when in master branch) git tag (shows you all the existing tags) -> git tag v5.11.2 -> git push --tags

## delete a tag with git command line [24 Feb 2020]:
# Example: git tag -d v5.9.3

## see all existing tags with git command line [24 Feb 2020]:
$ git tag

## see the commit log on a branch [24 Feb 2020]:
$ git log <branch_name>
#Example:
$ git log master

## to get the value of a config variable with git command line [24 Feb 2020]:
# Example: git config --get user.email

## to set the value of a config variable with git command line [24 Feb 2020]:
# Example: git config user.email nicolas.berta@gmail.com
# If you want to do it on all repositories:
# Example: git config --global user.email nicolas.berta@gmail.com

## install lightgbm python package [25 Feb 2020]:
# pip install lightgbm
# if failed with error: "Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib", then:
# in mac: brew install libomp

## find the version of an installed pythonn package in python environment [25 Feb 2020]:
# Example:
>>> import sklearn
>>> print(sklearn.__version__)

## use pipenv to create a virtualenv for your project and install new packages [02 Mar 2020]:
# install pipenv:
# $ pip install pipenv 
# or in Mac:
# $ brew install pipenv
# go to the root directory of your project and install a package using pipenv:
# Example:
$ cd project_root_dir
$ pipenv install tensorflow~=1.15.0
# to find out where the new environment python is:
$ pipenv shell
$ which python
$ exit


## to sync your python project with packages in the Pipfile.lock using pipenv [02 Mar 2020]:
# pipenv sync --dev
# This syncs/installs all the project packages in the Pipfile.lock for the project specific python environment


## fix matplotlib backend issue in Mac [02 Mar 2020]:
$ cat > ~/.matplotlib/matplotlibrc
backend: TkAgg

# install a python package from package source [12 Nov 2020]:
$ pip install /path/to/package/folder/
In an environment:
$ cd path/to/environment/folder
$ pipenv run pip install path/to/package/folder/

## test a prediction job in elp
$ cd prediction
$ pipenv install pytest
$ pipenv run pytest -k CASE_XGBOOST_TRAIN_FULL .

## install a python package ignoring the installed version [21 Jan 2021]:
# Example:
$ pip install llvmlite --ignore-installed

## add kernel of global python environment to jupyter notebook   [24 June 2021]:
# In the virtual environment you want to register:
$ cd path/to/folder_name
$ python -m ipykernel install --display-name <NAME> --name <NAME> --user
# or:
# ipython kernel install --name <NAME> --user
# Example:
$ python -m ipykernel install --name dst --display-name dst --user
# if you want to do this with a poetry env you can put poetry run before that command
# then run jupyter notebook and load the notebook file you want to run. In menue bar, 
# go to Kernel --> Change Kernel --> and select the kernel name you specified in <NAME>

## ignore any local changes and just update to the remote master branch in git [29 July 2021]:
$ git fetch
$ git reset --hard origin/master
# If you have local changes that you want to clean, you might have to do the following first:
$ git reset --hard
$ git clean -df 

## get a jb activation code [28 March 2022]:
For now use this:
5UEOFI0I1W-eyJsaWNlbnNlSWQiOiI1VUVPRkkwSTFXIiwibGljZW5zZWVOYW1lIjoiRWx1bGEgR3JvdXAiLCJhc3NpZ25lZU5hbWUiOiJOaW1hIFJhbWV6YW5pIiwiYXNzaWduZWVFbWFpbCI6Im5pbWEucmFtZXphbmlAZWx1bGFncm91cC5jb20iLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOnRydWUsInByb2R1Y3RzIjpbeyJjb2RlIjoiUEMiLCJmYWxsYmFja0RhdGUiOiIyMDIyLTAzLTA1IiwicGFpZFVwVG8iOiIyMDIzLTAzLTA0IiwiZXh0ZW5kZWQiOmZhbHNlfSx7ImNvZGUiOiJQUEMiLCJmYWxsYmFja0RhdGUiOiIyMDIyLTAzLTA1IiwicGFpZFVwVG8iOiIyMDIzLTAzLTA0IiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBXUyIsImZhbGxiYWNrRGF0ZSI6IjIwMjItMDMtMDUiLCJwYWlkVXBUbyI6IjIwMjMtMDMtMDQiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUFNJIiwiZmFsbGJhY2tEYXRlIjoiMjAyMi0wMy0wNSIsInBhaWRVcFRvIjoiMjAyMy0wMy0wNCIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQQ1dNUCIsInBhaWRVcFRvIjoiMjAyMy0wMy0wNCIsImV4dGVuZGVkIjp0cnVlfV0sIm1ldGFkYXRhIjoiMDEyMDIyMDMwN0NTQUEwMDYwMDkiLCJoYXNoIjoiMzE2NzgyNjUvMTQyNjUzNjY6LTEyNjMxODcyNjMiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6dHJ1ZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOnRydWV9-UFfFng4KDOS8QzSEPOYZ9PokPV+dqhCwBhTXRxcd1ePxISWOBZkj0dW8sixc8k0B1vlPC7H7IU/kFuE/tARrtrW9/Gg5LnbIM/m4gOQOZxaQyxdu3whG6SSHaq1ubTaKPMFoEeliwqVoHzBmOjXGJqCE2wb3ny8NBsyhB+q8gTAQ+iSFt9WSFpAfi+Zb4mMPD4iDEQfSwbZgJ4bsULB53QubgJRZX9zkIyWBK+X8350aO55bclS9JETJEgJ6E4NMrKxTVMVtakZVn2hEw2KgJC2ATmGB92k1+naxgI9oV7neRqAaAWdDDoP1Re76aB1n6WGhwTfocknuMdTY99EwXA==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDCP4uk4SlVdA5nuA3DQC+NsEnZS9npFnO0zrmMWcz1++q2UWJNuGTh0rwi+3fUJIArfvVh7gNtIp93rxjtrQAuf4/Fa6sySp4c32MeFACfC0q+oUoWebhOIaYTYUxm4LAZ355vzt8YeDPmvWKxA81udqEk4gU9NNAOz1Um5/8LyR8SGsSc4EDBRSjcMWMwMkYSauGqGcEUK8WhfplsyF61lKSOFA6VmfUmeDK15rUWWLbOMKgn2cxFA98A+s74T9Oo96CU7rp/umDXvhnyhAXSukw/qCGOVhwKR8B6aeDtoBWQgjnvMtPgOUPRTPkPGbwPwwDkvAHYiuKJ7Bd2wH7rAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBAB2J1ysRudbkqmkUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/wi9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD

## create a python virtual environment with virtualenv [28 March 2022]:
# If you have not installed virtualenv before:
$ pip install --user virtualenv
$ virtualenv myenv
# where myenv can be replaced with the name you want for your virtual environment. 
# The virtual environment can be found in the myenv folder. 
# For Python >= 3.3, you can create a virtual environment with:
$ python -m venv myenv
# After you have created your virtual environment, you can activate the virtual environment with:
$ source myenv/bin/activate
# To deactivate the virtual environment, you can run deactivate. 
# To delete the virtual environment you just need to remove the folder with the virtual environment like: 
$ rm -r myenv

## create a python virtual environment with anaconda [28 March 2022]:
$ conda create -n myenv
# where myenv is the name of your new environment. 
# If you want a specific Python version that is not your current version, you can type:
$ conda create -n myenv python=3.6
# The environment is then stored in the envs folder in your Anaconda directory. 
# After you have created the enviroment, you can activate it by typing:
$ conda activate myenv
# If you now run python, you’ll see that you are in your freshly created virtual environment. 
# To deactivate the environment you can type conda deactivate and you can list all the available environments on 
# your machine with conda env list. 
# To remove an enviroment you can type:
$ conda env remove -n myenv
# After creating your environment, you can install the packages you need besides the one already installed by conda.

## Add Virtual Environment to Jupyter Notebook [28 March 2022]:
# First, make sure your environment is activated
# Second, install ipykernel which provides the IPython kernel for Jupyter if not installed:
$ pip install --user ipykernel
# Next you can add your virtual environment to Jupyter by typing:
$ python -m ipykernel install --user --name=myenv
# This should print the following:
# Installed kernelspec myenv in /home/user/.local/share/jupyter/kernels/myenv

## see which kernels are available in jupyter notebook [28 March 2022]:
$ jupyter kernelspec list
Now, to uninstall/remove the kernel from jupyter notebook [28 March 2022]:
$ jupyter kernelspec uninstall myenv

## change default keyboard shortcuts in pyCharm [28 March 2022]:
# in pycharm go to settings 
# (in Mac in the menu bar left side click on PyCharm beside File --> preferences)
# (in Windows click on the settings icon in the right side of the bar)
# Appearance & Behaviour -> Keymap
# Choose your action and change key. For example for running selected code in console and 
# change it from Alt + Shift + E to ctrl + enter (like R Studio):
# Settings -> Keymap - Other -> Execute selection in Python Console --> add keyboard shortcut
# and just type your desired shortcut (Ctrl + Enter)
# You can keep the old shortcut or remove it if you like

## download sample eventlog for prediction
# https://www.kaggle.com/code/bechorfamedelamine/customer-behaviour-and-product-efficiency/data?select=2019-Oct.csv
 
## find non UTF-8 encoding in a script file by R Studio [14 April 2022]:
# go to Edit -> Find (Ctrl + F) and search for [^\x00-\x7F] with enabled Regex field in the search bar

## How Felix fixed my pipx and aws issue in Mac (order of execution is bottom to top) [28 April 2022]:
% curl -sSL https://install.python-poetry.org | python3
% pip3 uninstall awscli
% which aws
% python3 -m pipx ensurepath
$ which pipx
$ python3 -m pip install pipx
% python3 -m pip install aws-mfa
% which python3
% python3 --version
% python --version
% sudo nano /etc/paths
% pip3 install aws-mfa
% which pip3
% which pip
% rm $(which aws-mfa)
% echo $PATH
% which aws-mfa
% pipx install jobwrangler
% pip3 show aws-mfa 
% pyenv install 3.7.12
% xcode-select --install
% echo 'export PATH="$PYENV_ROOT/bin:$PATH"' >> ~/.zprofile
% echo 'eval "$(pyenv init --path)"' >> ~/.zprofile
% exec $SHELL
% curl https://pyenv.run | bash
% python3 --version
% which pip
% softwareupdate --all --install --force
% pyenv install 3.7.13 
% pyenv install 3.7.9
% which awscli
% pip3 install awscli --user
% which aws
% rm /usr/local/bin/aws
% which aws
% python3 -m pipx ensurepath
% python3 -m pip install pipx
% python3 -m pip install aws-mfa



## test equality of two pandas dataframes [2 May 2022]:
# Example:
>>> pd.testing.assert_frame_equal(output, expected_output)

## Move a committed change into a new branch [10 May 2022]:
$ git branch newbranch      # Create a new branch, saving the desired commits
$ git checkout master       # checkout master, this is the place you want to go back
$ git reset --hard HEAD~3   # Move master back by 3 commits (Make sure you know how many commits you                               # need to go back)
$ git checkout newbranch    # Go to the new branch that still has the desired commits


